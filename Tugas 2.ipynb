{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193d1f1-3ef6-451f-b7a5-05ffe69bdc28",
   "metadata": {},
   "source": [
    "<b>TUGAS 2<b>\n",
    "<b>ROHADI<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de5d7b1-0ed0-4c84-b1eb-4b9358e18e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (4.44.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: torch in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bd0cd-6c54-41ea-b8c9-44124ead70f7",
   "metadata": {},
   "source": [
    "<b>Dataset<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c3eb23-b25c-4670-9dd2-657e924c3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'C:/Users/rohad/liputan6_data.tar.gz'\n",
    "tar = tarfile.open(file, \"r:gz\")\n",
    "tar.extractall(path=\"dataset_directory\")\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb254423-7542-4a1d-95f6-ba3d6d226187",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf C:/Users/rohad/liputan6_data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecc09de-5674-4981-a8ae-1e5abf68182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate datasets==2.17.1 evaluate==0.4.1 seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e05a08-1fd1-44c1-8a50-77c2f7fdfd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: notebook in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter) (7.0.8)\n",
      "Collecting qtconsole (from jupyter)\n",
      "  Downloading qtconsole-5.5.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter) (7.10.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter) (6.28.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.11 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.11 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from notebook->jupyter) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from notebook->jupyter) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from notebook->jupyter) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from notebook->jupyter) (0.2.3)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter)\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.4.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook->jupyter) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.32.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2024.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2024.7.4)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading webcolors-24.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter)\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 92.2/139.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.4/139.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "   ---------------------------------------- 0.0/214.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 92.2/214.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 214.4/214.4 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.5/2.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.3 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.2/2.3 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading qtconsole-5.5.2-py3-none-any.whl (123 kB)\n",
      "   ---------------------------------------- 0.0/123.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 123.4/123.4 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "   ---------------------------------------- 0.0/93.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 93.5/93.5 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading webcolors-24.8.0-py3-none-any.whl (15 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.4/66.4 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Installing collected packages: widgetsnbextension, webcolors, uri-template, types-python-dateutil, qtpy, jupyterlab-widgets, jsonpointer, fqdn, arrow, isoduration, ipywidgets, qtconsole, jupyter-console, jupyter\n",
      "Successfully installed arrow-1.3.0 fqdn-1.5.1 ipywidgets-8.1.3 isoduration-20.11.0 jsonpointer-3.0.0 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.11 qtconsole-5.5.2 qtpy-2.4.1 types-python-dateutil-2.9.0.20240316 uri-template-1.3.0 webcolors-24.8.0 widgetsnbextension-4.0.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b936ff98-b3ae-45a2-8a6f-519e6d6e63f0",
   "metadata": {},
   "source": [
    "<b>Processing Dataset<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b038f3-6fef-4366-bcf9-f3b8f520524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import BertTokenizer, BertModel, EncoderDecoderModel, TrainingArguments, Trainer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b543a8d2-d087-4ae8-82b2-8f421ea14676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 193883\n",
      "eval data: 10972\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "train_file = glob.glob(\"liputan6_data/canonical/train/*.json\")\n",
    "train_file.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "eval_file = glob.glob(\"liputan6_data/canonical/test/*.json\")\n",
    "eval_file.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "train_data = []\n",
    "eval_data = []\n",
    "\n",
    "for i in train_file:\n",
    "  with open(i, \"r\", encoding=\"utf-8\") as f:\n",
    "    d = json.load(f)\n",
    "    train_data.append(d)\n",
    "\n",
    "for i in eval_file:\n",
    "  with open(i, \"r\", encoding=\"utf-8\") as f:\n",
    "    d = json.load(f)\n",
    "    eval_data.append(d)\n",
    "\n",
    "print(f\"train data: {len(train_data)}\")\n",
    "print(f\"eval data: {len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55fecf15-d3b5-440b-b116-74e14831e09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'url', 'clean_article', 'clean_summary', 'extractive_summary'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198b1ad6-97cc-4475-8a5f-a7595fdf616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:5000]\n",
    "eval_data = eval_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129ab3b3-3758-4d57-a7b9-cc2048d184c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def custom_join(words):\n",
    "  result = ' '.join(words)\n",
    "  result = result.replace(\"Liputan6 . com\", \"Liputan6.com\")\n",
    "  result = result.replace(\" , \", \", \")\n",
    "  result = result.replace(\" . \", \". \")\n",
    "  result = result.replace(\" ( \", \" (\")\n",
    "  result = result.replace(\" ) \", \") \")\n",
    "  return result\n",
    "\n",
    "\n",
    "def make_dataset_df(data):\n",
    "  clean_article = []\n",
    "  clean_summary = []\n",
    "\n",
    "  for item in data:\n",
    "    clean_article_sentence = []\n",
    "    for arr in item['clean_article']:\n",
    "      clean_article_sentence.extend(arr)\n",
    "    joined_str1 = custom_join(clean_article_sentence)\n",
    "    clean_article.append(joined_str1)\n",
    "\n",
    "    clean_summary_sentence = []\n",
    "    for arr in item['clean_summary']:\n",
    "      clean_summary_sentence.extend(arr)\n",
    "    joined_str2 = custom_join(clean_summary_sentence)\n",
    "    clean_summary.append(joined_str2)\n",
    "\n",
    "  df = pd.DataFrame({'clean_article': clean_article, 'clean_summary': clean_summary})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de88bde-804f-4cb4-b714-8cab705ced6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_dataset_df(train_data)\n",
    "eval_df = make_dataset_df(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c4a406-2ce5-4633-9b1b-dc179f514bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_article</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liputan6.com, Ambon : Partai Bulan Bintang wil...</td>\n",
       "      <td>Konflik Ambon telah berlangsung selama tiga ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liputan6.com, Denpasar : Berbeda dengan sebagi...</td>\n",
       "      <td>Masyarakat Bali merayakan Tahun Baru dengan tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liputan6.com, Jakarta : Partai Keadilan bertek...</td>\n",
       "      <td>Partai Keadilan menargetkan tambahan sejuta pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liputan6.com, Jakarta : Sekitar Rumah Makan Ay...</td>\n",
       "      <td>Pascaledakan granat di depan Rumah Makan Ayam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liputan6.com, Jambi : Ratusan hektare sawah di...</td>\n",
       "      <td>Bencana Banjir di Jambi, juga mengakibatkan ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Liputan6.com, Makassar : Pengadilan Negeri Mak...</td>\n",
       "      <td>Ratusan mahasiswa dan dosen nekat menutup jala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Liputan6.com, Medan : Proses pembentukan dua p...</td>\n",
       "      <td>Pemisahan provinsi dianggap hanya akan menamba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Liputan6.com, Pekanbaru : Ratusan orang yang t...</td>\n",
       "      <td>Ratusan anggota Forum Masyarakat Lancang Kunin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Liputan6.com, Jember : Harga bawang merah di k...</td>\n",
       "      <td>Akibat pasokan membludak, harga bawang merah d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Liputan6.com, Banda Aceh : Sebanyak 250 prajur...</td>\n",
       "      <td>Ratusan personel Yonif Linud 432 yang tergabun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_article  \\\n",
       "0     Liputan6.com, Ambon : Partai Bulan Bintang wil...   \n",
       "1     Liputan6.com, Denpasar : Berbeda dengan sebagi...   \n",
       "2     Liputan6.com, Jakarta : Partai Keadilan bertek...   \n",
       "3     Liputan6.com, Jakarta : Sekitar Rumah Makan Ay...   \n",
       "4     Liputan6.com, Jambi : Ratusan hektare sawah di...   \n",
       "...                                                 ...   \n",
       "4995  Liputan6.com, Makassar : Pengadilan Negeri Mak...   \n",
       "4996  Liputan6.com, Medan : Proses pembentukan dua p...   \n",
       "4997  Liputan6.com, Pekanbaru : Ratusan orang yang t...   \n",
       "4998  Liputan6.com, Jember : Harga bawang merah di k...   \n",
       "4999  Liputan6.com, Banda Aceh : Sebanyak 250 prajur...   \n",
       "\n",
       "                                          clean_summary  \n",
       "0     Konflik Ambon telah berlangsung selama tiga ta...  \n",
       "1     Masyarakat Bali merayakan Tahun Baru dengan tr...  \n",
       "2     Partai Keadilan menargetkan tambahan sejuta pe...  \n",
       "3     Pascaledakan granat di depan Rumah Makan Ayam ...  \n",
       "4     Bencana Banjir di Jambi, juga mengakibatkan ra...  \n",
       "...                                                 ...  \n",
       "4995  Ratusan mahasiswa dan dosen nekat menutup jala...  \n",
       "4996  Pemisahan provinsi dianggap hanya akan menamba...  \n",
       "4997  Ratusan anggota Forum Masyarakat Lancang Kunin...  \n",
       "4998  Akibat pasokan membludak, harga bawang merah d...  \n",
       "4999  Ratusan personel Yonif Linud 432 yang tergabun...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b32c208b-5b46-4239-9ecf-0c2c649b282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_article</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liputan6.com, Jakarta : Kepolisian Daerah Riau...</td>\n",
       "      <td>Kapolda Riau baru Brigjen Pol. Johny Yodjana b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liputan6.com, Jakarta : Bank Indonesia dinilai...</td>\n",
       "      <td>Kendati Bank Sentral AS menurunkan suku bungan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liputan6.com, Jakarta : Berbagai kendala mengh...</td>\n",
       "      <td>Pemerintah bermaksud akan lebih mengandalkan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liputan6.com, Jakarta : Penghapusan beberapa p...</td>\n",
       "      <td>Revisi Kepmennaker Nomor 78 Tahun 2001, dinila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liputan6.com, Jakarta : Operasi Sadar Jaya yan...</td>\n",
       "      <td>Polisi menangkap 32 pengunjung Diskotik Mileni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Liputan6.com, Jakarta : Ketua Asosiasi Tekstil...</td>\n",
       "      <td>Sejumlah pengusaha tekstil berharap pemerintah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Liputan6.com, Jember : Sebanyak 394 gerbong ke...</td>\n",
       "      <td>PT Pusri tak lagi menyewa 394 gerbong milik PT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Liputan6.com, Jakarta : Presiden Abdurrahman W...</td>\n",
       "      <td>Sekali lagi, Presiden Wahid membantah rencana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Liputan6.com, Medan : Arus pengungsi Aceh eks ...</td>\n",
       "      <td>Pemda Sumatra Utara kewalahan menangani pengun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Liputan6.com, Jakarta : Cadangan pakan ternak ...</td>\n",
       "      <td>Larangan impor jagung menyebabkan pasokan jagu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_article  \\\n",
       "0    Liputan6.com, Jakarta : Kepolisian Daerah Riau...   \n",
       "1    Liputan6.com, Jakarta : Bank Indonesia dinilai...   \n",
       "2    Liputan6.com, Jakarta : Berbagai kendala mengh...   \n",
       "3    Liputan6.com, Jakarta : Penghapusan beberapa p...   \n",
       "4    Liputan6.com, Jakarta : Operasi Sadar Jaya yan...   \n",
       "..                                                 ...   \n",
       "495  Liputan6.com, Jakarta : Ketua Asosiasi Tekstil...   \n",
       "496  Liputan6.com, Jember : Sebanyak 394 gerbong ke...   \n",
       "497  Liputan6.com, Jakarta : Presiden Abdurrahman W...   \n",
       "498  Liputan6.com, Medan : Arus pengungsi Aceh eks ...   \n",
       "499  Liputan6.com, Jakarta : Cadangan pakan ternak ...   \n",
       "\n",
       "                                         clean_summary  \n",
       "0    Kapolda Riau baru Brigjen Pol. Johny Yodjana b...  \n",
       "1    Kendati Bank Sentral AS menurunkan suku bungan...  \n",
       "2    Pemerintah bermaksud akan lebih mengandalkan s...  \n",
       "3    Revisi Kepmennaker Nomor 78 Tahun 2001, dinila...  \n",
       "4    Polisi menangkap 32 pengunjung Diskotik Mileni...  \n",
       "..                                                 ...  \n",
       "495  Sejumlah pengusaha tekstil berharap pemerintah...  \n",
       "496  PT Pusri tak lagi menyewa 394 gerbong milik PT...  \n",
       "497  Sekali lagi, Presiden Wahid membantah rencana ...  \n",
       "498  Pemda Sumatra Utara kewalahan menangani pengun...  \n",
       "499  Larangan impor jagung menyebabkan pasokan jagu...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e2b551-d77d-48f9-8184-7a11c3b30f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Liputan6.com, Makassar : Kondisi kesehatan Wakil Komandan Batalyon Resimen I Brigade Mobil Ajun Komisaris Polisi Tukijan membaik [ baca : Wadan Brimob Ambon Tertembak ]. Namun dalam pengamatan SCTV, baru-baru ini, Tukijan yang sempat krtitis karena tertembak peluru nyasar di bagian dahi sebelah kanan, masih terbaring lemah. Tukijan yang juga Wakil Komandan Satuan Tugas Operasi Mutiara Empat di Ambon, Maluku, sempat dalam kondisi kritis selama empat hari. Tukijan dievakuasi dari Ambon Jumat silam dan kini dirawat di Rumah Sakit Pelamonia Makassar, Sulawesi Selatan. Menurut dokter di rumah sakit tersebut, korban kini sudah dapat menggerakkan otot motoriknya tanpa bantuan alat elektrik. Kepala Dinas Penerangan TNI Angkatan Darat Brigadir Jenderal Ismet menyatakan, insiden tembak menembak itu terjadi di perbatasan Desa Tantui dan Galala adalah antara Brimob dan Marinir. Sementara menurut Kapolda Sulsel Inspektur Jenderal Polisi Firman Gani, jenis peluru yang bersarang di kepala korban berasal dari senjata jenis AK 47 [ baca : Wadan Brimob Ambon Ditembak Menggunakan AK 47 ]. (YYT/Iwan Taruna) .'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_article'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad309063-8b79-4fd1-bf27-ba54ec0db162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ajun Komisaris Polisi Tukijan, korban baku tembak di Ambon kondisinya mulai membaik. Peluru nyasar yang menembus dahi korban berasal dari senjata jenis AK .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_summary'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "158fb7b5-b246-434d-8a37-1b055883ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75258157-9b72-426d-819d-6c9034c64c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['clean_article', 'clean_summary'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb1ad606-67a4-41ac-98cd-069725a29f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['clean_article', 'clean_summary'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5e0d178-254e-468f-8848-57ee4caac2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('cahya/bert-base-indonesian-1.5G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f18fc43c-6928-424b-bc56-fe93915dec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tokenize_data function to accept the tokenizer as a parameter\n",
    "def tokenize_data(example, tokenizer):\n",
    "    input_encoding = tokenizer(example['clean_article'], \n",
    "                                padding='max_length', \n",
    "                                truncation=True, \n",
    "                                max_length=512,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "    target_encoding = tokenizer(example['clean_summary'], \n",
    "                                padding='max_length', \n",
    "                                truncation=True, \n",
    "                                max_length=128,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "    return {\n",
    "        'input_ids': input_encoding['input_ids'],\n",
    "        'attention_mask': input_encoding['attention_mask'],\n",
    "        'labels': target_encoding['input_ids']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbab8182-f0a5-44f8-8497-6ff88d6a4ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 5000/5000 [00:11<00:00, 430.96 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 500/500 [00:06<00:00, 82.55 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# Map the function with tokenizer as an argument\n",
    "tokenized_train = train_dataset.map(tokenize_data, batched=True, num_proc=4, fn_kwargs={'tokenizer': tokenizer})\n",
    "tokenized_eval = eval_dataset.map(tokenize_data, batched=True, num_proc=4, fn_kwargs={'tokenizer': tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0df1a78-da64-4ca5-ae31-b32f58f4a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b2227ff-e3c4-41c7-ba39-1bffb2a39633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "570fa3c4-5dbb-4ed6-94df-e7c1d94b3e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# make Bert2Bert (Encoder-Decoder model)\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained('cahya/bert-base-indonesian-1.5G', 'cahya/bert-base-indonesian-1.5G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa3bdb83-d650-4fc1-96a7-92a36ba0093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special tokens\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28843da3-c810-4715-9d75-0c9b66bcc1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "749045c5-b396-4c7b-a501-50a090837f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations for the encoder and decoder\n",
    "model.config.encoder.max_length = 512\n",
    "model.config.decoder.max_length = 128\n",
    "model.config.decoder.min_length = 12\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.early_stopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5268ef70-4daf-4675-ac77-3827258f7dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (0.23.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohad\\anaconda3\\envs\\cuda_test\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3824271a-fda1-4410-a520-fea1d823985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33184965-ec8e-454f-88ae-03f665435e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b67bfb0-813d-4f75-8b19-27cd85905082",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=4,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    eval_strategy='epoch',           # updated parameter name\n",
    "    save_strategy='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cba4601-b9c2-4499-894a-e48fca9cf0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9897a8a-7ea5-4666-9fb9-c57e76a5d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 18:48:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>0.964951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.913296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.905551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=0.8885666852315267, metrics={'train_runtime': 67746.0156, 'train_samples_per_second': 0.221, 'train_steps_per_second': 0.028, 'total_flos': 9201879613440000.0, 'train_loss': 0.8885666852315267, 'epoch': 3.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2b32b-5391-4ab3-9e30-e73bc60ef86d",
   "metadata": {},
   "source": [
    "<b>Evaluasi Data<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b0971ca-c7b5-43b6-bf29-9654379979d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohad\\anaconda3\\envs\\cuda_test\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 05:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate(tokenized_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1e158f6-ec98-4a19-9ed9-e7f89068fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9055507183074951, 'eval_runtime': 354.7589, 'eval_samples_per_second': 1.409, 'eval_steps_per_second': 0.352, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
